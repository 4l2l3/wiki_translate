h1. Meep
*Last Modified*: [[LastModified(Meep)]]
h2. Description

_From the [[Meep]] Homepage, http://ab-initio.mit.edu/wiki/index.php/Meep_: [[Meep]] (or MEEP) is a free finite-difference time-domain (FDTD) simulation software package developed at MIT to model electromagnetic systems, along with our MPB eigenmode package. Its features include: 
**  Free software under the GNU GPL.
** Simulation in 1d, 2d, 3d, and cylindrical coordinates.
** Distributed memory parallelism on any system supporting the MPI standard. Portable to any Unix-like system (GNU/Linux is fine).
** Arbitrary anisotropic electric permittivity ε and magnetic permeability μ, along with dispersive ε(ω) and μ(ω) (including loss/gain) and nonlinear (Kerr &amp; Pockels) dielectric and magnetic materials, and electric/magnetic conductivities σ.
** PML absorbing boundaries and/or perfect conductor and/or Bloch-periodic boundary conditions.
** Exploitation of symmetries to reduce the computation size — even/odd mirror symmetries and 90°/180° rotations.
** Complete scriptability — either via a Scheme scripting front-end (as in libctl and MPB), or callable as a C++ library.
** Field output in the HDF5 standard scientific data format, supported by many visualization tools.
** Arbitrary material and source distributions.
** Field analyses including flux spectra, frequency extraction, and energy integrals; completely programmable.
** Multi-parameter optimization, root-finding, integration, etcetera (via libctl). 
Meep officially stands for MIT Electromagnetic Equation Propagation, but we also have several unofficial meanings of the acronym. 

h2. Version

** *1.1.1*

h2. Authorized Users

** All Circe Users

h2. Platform

** @circe@ cluster

h2. Running [[Meep]] on the Cluster
It is highly recommended that you read the tutorials on using [[Meep]] from the [[Meep]] webpage:
** [[Meep]] tutorial: http://ab-initio.mit.edu/wiki/index.php/Meep_Tutorial

h3. [[Meep]] Utilities
Ensure that you've loaded the module @apps/meep/1.1.1@ into your environment to access the various HDF5 utilities for converting and working with output data.  Load it persistently so that we can avoid having to deal with it again later:

<pre>
[user@login0 ~]$ module add apps/meep/1.1.1
[user@login0 ~]$ module initadd apps/meep/1.1.1
</pre>

Loading the [[Meep]] module will automatically provide the following dependencies:
** compilers/intel/10.1.018.x86_64
** openmpi/1.2.7-x86_64-intel-10.1.018
** apps/szip/2.0
** apps/hdf5/1.6.9
** apps/libctl/3.1
** apps/h5utils/1.12.1
** apps/harminv/1.3.1

h3. Running a Parallel Job
To run Meep, we will use the @run@ command which creates our job script and submits our job to the cluster for us.  We will also use the /work filesystem since [[Meep]] relies on HDF5's parallel I/O facilities:
<pre>
[user@login0 ~]$ cd $WORK
[user@login0 user]$ ls
input.ctl
[user@login0 user]$ run -b -t 1:00:00 -n 4 meep-mpi input.ctl
...
</pre>
Here, we run [[Meep]] with 4 processors for one hour, specifying the input ctl file `input.ctl`.  See the tutorials linked above for information on creating the ctl (Scheme-based) input file.  For more information on using the @run@ command, please see [[Run here]].

h2. More Job Information
See the following for more detailed job submission information:
** [[gridEngineUsers|SGE User's Guide]]
** [[gridEnginePolicy|Scheduling and Dispatch Policies]]
** [[gridEngineTechn|Advanced Submit Techniques]]
h2. Reporting Bugs
Report bugs to the Information Technology Helpdesk at help@usf.edu
